{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x155527cf0910>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import sys\n",
    "p = os.path.abspath('/global/homes/q/qnicolas/')\n",
    "if p not in sys.path:\n",
    "    sys.path.append(p)\n",
    "\n",
    "from tools.e5tools import *\n",
    "xr.set_options(display_style='text') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mountains=         {\"vietnam\"    :([102,115,10,19.5],\"Annamite range (Vietnam)\",240,10),\n",
    "                    \"ghats\"      :([68,80,7.5,17]   ,\"Western Ghats\"           ,70 ,6 ),\n",
    "                    \"madagascar\" :([40,60,-25,-12]  ,\"Madagascar\"              ,280,3 ),\n",
    "                    \"myanmar\"    :([80,102,7,27]    ,\"Myanmar\"                 ,60 ,7 ),\n",
    "                    \"newbritain\" :([148,155,-12,0]  ,\"New Britain\"             ,320,7 ),\n",
    "                    \"philippines\":([118,130,10,22]  ,\"Philippines\"             ,225,12),\n",
    "                    \"sumatra\"    :([90,110,-6,6]    ,\"Bukit Barisan (Sumatra)\" ,70 ,11),\n",
    "                    \"malaysia\"   :([97,107,1,10]    ,\"Malaysia\"                ,225,11),\n",
    "                    \"bayofbengal\":([82,90,12,18],),\n",
    "                    \"ghatswide\"  :([68,85,7.5,17]  ,),\n",
    "                    \"myanmarwide\"     :([85,105,12,29]  ,),\n",
    "                    \"newbritainwide\"  :([146,155,-12,0]  ,),\n",
    "                   }\n",
    "\n",
    "precip_boxes = {\"vietnam\"    :[107  ,  19  , 110.5, 14   ,2  ],\n",
    "                \"ghats\"      :[ 75  ,   9  ,  72.5, 16   ,2  ],\n",
    "                \"madagascar\" :[ 52  , -14.5,  49  , -24.5,2.5],\n",
    "                \"myanmar\"    :[ 98  ,  11  ,  90  , 21   ,4  ],\n",
    "                \"newbritain\" :[154  , - 6  , 150  , -8   ,2  ],\n",
    "                \"philippines\":[123.5,  19  , 127  , 11   ,3  ],\n",
    "                \"sumatra\"    :[ 98.5, - 2  ,  96  , 2    ,2.5],\n",
    "                \"malaysia\"   :[100.5,  10  , 105  , 4    ,2  ],\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tilted_rect(grid,x1,y1,x2,y2,width,reverse=False):\n",
    "    x = grid.longitude\n",
    "    y = grid.latitude\n",
    "    if reverse:\n",
    "        halfplane_para = (x-x1)*(y2-y1) - (x2-x1)*(y-y1) <=0\n",
    "    else:\n",
    "        halfplane_para = (x-x1)*(y2-y1) - (x2-x1)*(y-y1) >=0\n",
    "    sc_prod = (x-x1)*(x2-x1)+(y-y1)*(y2-y1)\n",
    "    halfplane_perp_up = sc_prod >= 0\n",
    "    halfplane_perp_dn = (x-x2)*(x1-x2)+(y-y2)*(y1-y2) >= 0\n",
    "    distance_across = np.sqrt((x-x1)**2+(y-y1)**2 - sc_prod**2/((x2-x1)**2+(y2-y1)**2))\n",
    "    return (halfplane_para*halfplane_perp_up*halfplane_perp_dn*(distance_across<width)).transpose('latitude','longitude')\n",
    "def crossslopeflow(u,v,angle):\n",
    "    return (u*np.sin(angle*np.pi/180)+v*np.cos(angle*np.pi/180))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# CLIMCAPS sdev - temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths=[]\n",
    "with open(\"/global/cscratch1/sd/qnicolas/CLIMCAPS_V2/url_daily.txt\",'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for f in lines:\n",
    "        if f[-58:-52] == \"201310\":\n",
    "            paths.append(f[-81:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pydap.client import open_url\n",
    "from pydap.cas.urs import setup_session\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "username = 'qnicolas'\n",
    "password = 'Surf@b3rkeley!'\n",
    "\n",
    "urls = [\"https://sounder.gesdisc.eosdis.nasa.gov/opendap/Aqua_Sounder_Level3/SNDRAQIML3CDCCP.2/\"+ path for path in paths]\n",
    "url_ex = urls[0]\n",
    "\n",
    "session = setup_session(username, password, check_url=url_ex)\n",
    "store = xr.backends.PydapDataStore.open(url_ex, session=session)\n",
    "ds = xr.open_dataset(store)\n",
    "\n",
    "climcaps_sdevs_201310 = 0.+0.*ds.sdev_air_temp_sdev.expand_dims({'time':pd.date_range(\"20131001\",\"20131010\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.68144130706787\n",
      "\n",
      "62.95948815345764\n",
      "\n",
      "72.17381429672241\n",
      "\n",
      "74.03774404525757\n",
      "\n",
      "78.38177537918091\n",
      "\n",
      "36.24507117271423\n",
      "\n",
      "83.1578996181488\n",
      "\n",
      "85.92022728919983\n",
      "\n",
      "61.21811366081238\n",
      "\n",
      "83.58768391609192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,url in enumerate(urls[:10]):\n",
    "    t=time.time()\n",
    "    session = setup_session(username, password, check_url=url)\n",
    "    store = xr.backends.PydapDataStore.open(url, session=session)\n",
    "    ds = xr.open_dataset(store)\n",
    "    climcaps_sdevs_201310[i]=ds.sdev_air_temp_sdev\n",
    "    print(time.time()-t)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computing daily&box means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=range(1998,2014)\n",
    "months_perregion = {\"vietnam\"    :[10],\n",
    "                    \"ghats\"      :[7],\n",
    "                    \"madagascar\" :[3,4],\n",
    "                    \"myanmar\"    :[6,7,8],\n",
    "                    \"newbritain\" :[6,7,8],\n",
    "                    \"philippines\":[11,12],\n",
    "                    \"sumatra\"    :[1,11,12],\n",
    "                    \"malaysia\"   :[11,12],\n",
    "                    \"myanmarwide\"   :[6,7,8],\n",
    "                    \"newbritainwide\":[6,7,8],\n",
    "                   }\n",
    "#\"ghats\"      :[6,7,8],#\"vietnam\"      :[10,11],\n",
    "\n",
    "#months_perregion = {\"vietnam\"    :[10],\n",
    "#                    \"ghats\"      :[7],\n",
    "#                    \"madagascar\" :[3],\n",
    "#                    \"myanmar\"    :[7],\n",
    "#                    \"newbritain\" :[7],\n",
    "#                    \"philippines\":[12],\n",
    "#                    \"sumatra\"    :[11],\n",
    "#                    \"malaysia\"   :[11],\n",
    "#                    \"bayofbengal\":[7],\n",
    "#                    \"ghatswide\":[6,8],\n",
    "#                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Create zarr groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 33163 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:35161</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:33163/status' target='_blank'>http://127.0.0.1:33163/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>64</li>\n",
       "  <li><b>Memory: </b>540.14 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:35161' processes=8 threads=64, memory=540.14 GB>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_regions = \"madagascar\",\"myanmar\",\"newbritain\",\"philippines\",\"sumatra\",\"malaysia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ghats\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.04 s, sys: 888 ms, total: 9.93 s\n",
      "Wall time: 36.8 s\n"
     ]
    }
   ],
   "source": [
    "years=range(2002,2014)\n",
    "CLIMCAPS_PATH = \"/global/cscratch1/sd/qnicolas/CLIMCAPS_V2/\"\n",
    "for name in ['ghats']:\n",
    "    print(name)\n",
    "    box=mountains[name][0]\n",
    "    months=months_perregion[name]\n",
    "    for m in months:\n",
    "        print(m)\n",
    "        preprocess = lambda ds: ds.swap_dims({'orbit_pass':'obs_time_tai93'}).rename(obs_time_tai93='time',lat='latitude',lon='longitude').spec_hum.isel(time=[1,0])\n",
    "        ds = xr.open_mfdataset(sorted(glob.glob(CLIMCAPS_PATH+\"daily/SNDR.AQUA.AIRS_IM.????{:02}*.L3_CLIMCAPS_QCC.std.v02_38.G.*.nc\".format(m))),preprocess=preprocess,combine='nested',concat_dim='time',parallel=True)\n",
    "        %time ds.reindex(latitude=list(reversed(ds.latitude))).sel(longitude=slice(box[0],box[1]),latitude=slice(box[3],box[2])).to_dataset().to_zarr(\"/global/cscratch1/sd/qnicolas/regionsData/L3_CLIMCAPS_QCC.spec_hum.2002-2015.{:02}.{}.zarr\".format(m,name),mode=\"w\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.37 s, sys: 301 ms, total: 3.67 s\n",
      "Wall time: 14.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x2aab4f22d8a0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years=range(2002,2014)\n",
    "CLIMCAPS_PATH = \"/global/cscratch1/sd/qnicolas/CLIMCAPS_V2/\"\n",
    "\n",
    "preprocess = lambda ds: ds.air_temp.assign_coords({'time':np.array(ds.obs_time_tai93[0])}).expand_dims('time').rename(lat='latitude',lon='longitude')\n",
    "ds = xr.open_mfdataset(sorted(glob.glob(CLIMCAPS_PATH+\"monthly/SNDR.AQUA.AIRS_IM.*.nc\")),preprocess=preprocess,combine='nested',concat_dim='time',parallel=True)\n",
    "%time ds.reindex(latitude=list(reversed(ds.latitude))).to_dataset().to_zarr(CLIMCAPS_PATH+\"monthly/L3_CLIMCAPS_QCC.air_temp.monthly.zarr\",mode=\"w\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myanmarwide\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.65 s, sys: 988 ms, total: 8.64 s\n",
      "Wall time: 34.4 s\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.1 s, sys: 914 ms, total: 8.01 s\n",
      "Wall time: 34.6 s\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.74 s, sys: 765 ms, total: 8.5 s\n",
      "Wall time: 35.8 s\n",
      "newbritainwide\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.11 s, sys: 833 ms, total: 7.94 s\n",
      "Wall time: 37.7 s\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.72 s, sys: 859 ms, total: 9.57 s\n",
      "Wall time: 43.9 s\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.11 s, sys: 902 ms, total: 9.01 s\n",
      "Wall time: 41.8 s\n"
     ]
    }
   ],
   "source": [
    "years=range(2002,2016)\n",
    "CLIMCAPS_PATH = \"/global/cscratch1/sd/qnicolas/CLIMCAPS_V2/\"\n",
    "for name in ['myanmarwide','newbritainwide']:\n",
    "    print(name)\n",
    "    box=mountains[name][0]\n",
    "    months=months_perregion[name]\n",
    "    for m in months:\n",
    "        print(m)\n",
    "        preprocess = lambda ds: ds.swap_dims({'orbit_pass':'obs_time_tai93'}).rename(obs_time_tai93='time',lat='latitude',lon='longitude').air_temp.isel(time=[1,0])\n",
    "        ds = xr.open_mfdataset(sorted(glob.glob(CLIMCAPS_PATH+\"daily/SNDR.AQUA.AIRS_IM.????{:02}*.L3_CLIMCAPS_QCC.std.v02_38.G.*.nc\".format(m))),preprocess=preprocess,combine='nested',concat_dim='time',parallel=True)\n",
    "        %time ds.reindex(latitude=list(reversed(ds.latitude))).sel(longitude=slice(box[0],box[1]),latitude=slice(box[3],box[2])).to_dataset().to_zarr(\"/global/cscratch1/sd/qnicolas/regionsData/L3_CLIMCAPS_QCC.air_temp.2002-2015.{:02}.{}.zarr\".format(m,name),mode=\"w\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128_132_v vietnam\n",
      "200110\n",
      "CPU times: user 11.5 s, sys: 957 ms, total: 12.4 s\n",
      "Wall time: 2min 14s\n",
      "200210\n",
      "CPU times: user 10.6 s, sys: 871 ms, total: 11.5 s\n",
      "Wall time: 2min 4s\n",
      "200310\n",
      "CPU times: user 10.2 s, sys: 997 ms, total: 11.2 s\n",
      "Wall time: 2min 3s\n",
      "200410\n",
      "CPU times: user 10.3 s, sys: 950 ms, total: 11.3 s\n",
      "Wall time: 2min 4s\n",
      "200510\n",
      "CPU times: user 10.3 s, sys: 950 ms, total: 11.2 s\n",
      "Wall time: 2min 5s\n",
      "200610\n",
      "CPU times: user 10.3 s, sys: 932 ms, total: 11.2 s\n",
      "Wall time: 2min 1s\n",
      "200810\n",
      "CPU times: user 9.68 s, sys: 1.22 s, total: 10.9 s\n",
      "Wall time: 2min 1s\n",
      "200910\n",
      "CPU times: user 9.64 s, sys: 1.16 s, total: 10.8 s\n",
      "Wall time: 2min 3s\n",
      "201010\n",
      "CPU times: user 9.58 s, sys: 1.22 s, total: 10.8 s\n",
      "Wall time: 2min 1s\n",
      "201110\n",
      "CPU times: user 9.67 s, sys: 1.33 s, total: 11 s\n",
      "Wall time: 2min 5s\n",
      "201210\n",
      "CPU times: user 10.2 s, sys: 1.41 s, total: 11.6 s\n",
      "Wall time: 2min 10s\n",
      "201310\n",
      "CPU times: user 10.3 s, sys: 1.41 s, total: 11.7 s\n",
      "Wall time: 2min 10s\n",
      "201410\n",
      "CPU times: user 10 s, sys: 1.3 s, total: 11.3 s\n",
      "Wall time: 2min 7s\n",
      "201510\n",
      "CPU times: user 10 s, sys: 1.44 s, total: 11.5 s\n",
      "Wall time: 2min 10s\n",
      "128_132_v myanmarwide\n",
      "200106\n",
      "CPU times: user 10.4 s, sys: 1.51 s, total: 11.9 s\n",
      "Wall time: 2min 9s\n",
      "200107\n",
      "CPU times: user 10.2 s, sys: 1.42 s, total: 11.6 s\n",
      "Wall time: 2min 13s\n",
      "200108\n",
      "CPU times: user 9.65 s, sys: 1.51 s, total: 11.2 s\n",
      "Wall time: 2min 8s\n",
      "200206\n",
      "CPU times: user 10.1 s, sys: 1.39 s, total: 11.5 s\n",
      "Wall time: 2min 9s\n",
      "200207\n",
      "CPU times: user 9.22 s, sys: 1.27 s, total: 10.5 s\n",
      "Wall time: 2min\n",
      "200306\n",
      "CPU times: user 9.32 s, sys: 1.45 s, total: 10.8 s\n",
      "Wall time: 2min 3s\n",
      "200307\n",
      "CPU times: user 9.41 s, sys: 1.42 s, total: 10.8 s\n",
      "Wall time: 2min\n",
      "200308\n",
      "CPU times: user 9.17 s, sys: 1.37 s, total: 10.5 s\n",
      "Wall time: 2min\n",
      "200406\n",
      "CPU times: user 9.23 s, sys: 1.44 s, total: 10.7 s\n",
      "Wall time: 2min 1s\n",
      "200407\n",
      "CPU times: user 9.06 s, sys: 1.33 s, total: 10.4 s\n",
      "Wall time: 1min 56s\n",
      "200408\n",
      "CPU times: user 9.3 s, sys: 1.41 s, total: 10.7 s\n",
      "Wall time: 2min\n",
      "200506\n",
      "CPU times: user 9.22 s, sys: 1.53 s, total: 10.7 s\n",
      "Wall time: 2min 3s\n",
      "200507\n",
      "CPU times: user 8.94 s, sys: 1.41 s, total: 10.3 s\n",
      "Wall time: 1min 59s\n",
      "200508\n",
      "CPU times: user 10.4 s, sys: 1.6 s, total: 12 s\n",
      "Wall time: 2min 8s\n",
      "200606\n",
      "CPU times: user 10.2 s, sys: 1.6 s, total: 11.8 s\n",
      "Wall time: 2min 9s\n",
      "200607\n",
      "CPU times: user 11.3 s, sys: 1.02 s, total: 12.3 s\n",
      "Wall time: 2min 8s\n",
      "200608\n",
      "CPU times: user 11.1 s, sys: 818 ms, total: 11.9 s\n",
      "Wall time: 2min 9s\n",
      "200706\n",
      "CPU times: user 11.1 s, sys: 901 ms, total: 12 s\n",
      "Wall time: 2min 11s\n",
      "200707\n",
      "CPU times: user 10.4 s, sys: 877 ms, total: 11.2 s\n",
      "Wall time: 2min 7s\n",
      "200708\n",
      "CPU times: user 10.4 s, sys: 1.07 s, total: 11.5 s\n",
      "Wall time: 2min 4s\n",
      "200806\n",
      "CPU times: user 10.7 s, sys: 824 ms, total: 11.5 s\n",
      "Wall time: 2min 10s\n",
      "200807\n",
      "CPU times: user 10.5 s, sys: 802 ms, total: 11.3 s\n",
      "Wall time: 2min 6s\n",
      "200808\n",
      "CPU times: user 11 s, sys: 908 ms, total: 11.9 s\n",
      "Wall time: 2min 9s\n",
      "200906\n",
      "CPU times: user 9.9 s, sys: 1.27 s, total: 11.2 s\n",
      "Wall time: 2min 7s\n",
      "200907\n",
      "CPU times: user 10.2 s, sys: 1.33 s, total: 11.5 s\n",
      "Wall time: 2min 4s\n",
      "200908\n",
      "CPU times: user 10.4 s, sys: 1.35 s, total: 11.7 s\n",
      "Wall time: 2min 11s\n",
      "201006\n",
      "CPU times: user 9.55 s, sys: 1.37 s, total: 10.9 s\n",
      "Wall time: 2min 2s\n",
      "201007\n",
      "CPU times: user 9.94 s, sys: 1.51 s, total: 11.5 s\n",
      "Wall time: 2min 10s\n",
      "201008\n",
      "CPU times: user 9.7 s, sys: 1.39 s, total: 11.1 s\n",
      "Wall time: 2min 5s\n",
      "201106\n",
      "CPU times: user 9.86 s, sys: 1.55 s, total: 11.4 s\n",
      "Wall time: 2min 10s\n",
      "201107\n",
      "CPU times: user 11 s, sys: 1.57 s, total: 12.6 s\n",
      "Wall time: 2min 23s\n",
      "201108\n",
      "CPU times: user 11 s, sys: 1.69 s, total: 12.7 s\n",
      "Wall time: 2min 26s\n",
      "201206\n",
      "CPU times: user 10.9 s, sys: 1.69 s, total: 12.6 s\n",
      "Wall time: 2min 25s\n",
      "201207\n",
      "CPU times: user 11 s, sys: 1.66 s, total: 12.6 s\n",
      "Wall time: 2min 25s\n",
      "201208\n",
      "CPU times: user 10.8 s, sys: 1.74 s, total: 12.5 s\n",
      "Wall time: 2min 25s\n",
      "201306\n",
      "CPU times: user 10.8 s, sys: 1.62 s, total: 12.5 s\n",
      "Wall time: 2min 23s\n",
      "201307\n",
      "CPU times: user 11.3 s, sys: 1.8 s, total: 13.1 s\n",
      "Wall time: 2min 30s\n",
      "201308\n",
      "CPU times: user 10.9 s, sys: 1.68 s, total: 12.6 s\n",
      "Wall time: 2min 23s\n",
      "201406\n",
      "CPU times: user 10.8 s, sys: 1.57 s, total: 12.3 s\n",
      "Wall time: 2min 22s\n",
      "201407\n",
      "CPU times: user 10.6 s, sys: 1.71 s, total: 12.4 s\n",
      "Wall time: 2min 23s\n",
      "201408\n",
      "CPU times: user 11.2 s, sys: 1.73 s, total: 12.9 s\n",
      "Wall time: 2min 27s\n",
      "201506\n",
      "CPU times: user 11.7 s, sys: 1.77 s, total: 13.5 s\n",
      "Wall time: 2min 31s\n",
      "201507\n",
      "CPU times: user 11.2 s, sys: 1.63 s, total: 12.9 s\n",
      "Wall time: 2min 27s\n",
      "201508\n",
      "CPU times: user 12.1 s, sys: 1.85 s, total: 14 s\n",
      "Wall time: 2min 42s\n",
      "128_132_v newbritainwide\n",
      "200106\n",
      "CPU times: user 11.3 s, sys: 1.74 s, total: 13.1 s\n",
      "Wall time: 2min 31s\n",
      "200107\n",
      "CPU times: user 10.9 s, sys: 1.17 s, total: 12.1 s\n",
      "Wall time: 2min 17s\n",
      "200108\n",
      "CPU times: user 10 s, sys: 748 ms, total: 10.7 s\n",
      "Wall time: 2min 1s\n",
      "200207\n",
      "CPU times: user 10.6 s, sys: 824 ms, total: 11.4 s\n",
      "Wall time: 2min 10s\n",
      "200208\n",
      "CPU times: user 10.4 s, sys: 757 ms, total: 11.1 s\n",
      "Wall time: 2min 1s\n",
      "200306\n",
      "CPU times: user 9.76 s, sys: 797 ms, total: 10.6 s\n",
      "Wall time: 2min\n",
      "200307\n",
      "CPU times: user 9.99 s, sys: 644 ms, total: 10.6 s\n",
      "Wall time: 2min\n",
      "200308\n",
      "CPU times: user 9.97 s, sys: 794 ms, total: 10.8 s\n",
      "Wall time: 2min 2s\n",
      "200406\n",
      "CPU times: user 9.36 s, sys: 1.36 s, total: 10.7 s\n",
      "Wall time: 2min\n",
      "200407\n",
      "CPU times: user 9.18 s, sys: 1.31 s, total: 10.5 s\n",
      "Wall time: 1min 59s\n",
      "200408\n",
      "CPU times: user 9.6 s, sys: 1.47 s, total: 11.1 s\n",
      "Wall time: 2min 3s\n",
      "200506\n",
      "CPU times: user 9.25 s, sys: 1.35 s, total: 10.6 s\n",
      "Wall time: 1min 59s\n",
      "200507\n",
      "CPU times: user 9.28 s, sys: 1.34 s, total: 10.6 s\n",
      "Wall time: 1min 59s\n",
      "200508\n",
      "CPU times: user 9.39 s, sys: 1.63 s, total: 11 s\n",
      "Wall time: 2min 3s\n",
      "200606\n",
      "CPU times: user 9.82 s, sys: 1.45 s, total: 11.3 s\n",
      "Wall time: 2min 6s\n",
      "200607\n",
      "CPU times: user 9.97 s, sys: 1.56 s, total: 11.5 s\n",
      "Wall time: 2min 9s\n",
      "200608\n",
      "CPU times: user 10 s, sys: 1.67 s, total: 11.7 s\n",
      "Wall time: 2min 10s\n",
      "200706\n",
      "CPU times: user 10 s, sys: 1.5 s, total: 11.6 s\n",
      "Wall time: 2min 2s\n",
      "200707\n",
      "CPU times: user 9.9 s, sys: 1.66 s, total: 11.6 s\n",
      "Wall time: 2min 8s\n",
      "200708\n",
      "CPU times: user 10.3 s, sys: 1.46 s, total: 11.8 s\n",
      "Wall time: 2min 10s\n",
      "200806\n",
      "CPU times: user 10 s, sys: 1.44 s, total: 11.5 s\n",
      "Wall time: 2min 5s\n",
      "200807\n",
      "CPU times: user 9.46 s, sys: 1.37 s, total: 10.8 s\n",
      "Wall time: 2min 1s\n",
      "200808\n",
      "CPU times: user 9.5 s, sys: 1.43 s, total: 10.9 s\n",
      "Wall time: 2min 1s\n",
      "200906\n",
      "CPU times: user 9.68 s, sys: 1.27 s, total: 11 s\n",
      "Wall time: 2min 1s\n",
      "200907\n",
      "CPU times: user 9.89 s, sys: 1.37 s, total: 11.3 s\n",
      "Wall time: 2min\n",
      "200908\n",
      "CPU times: user 10 s, sys: 1.44 s, total: 11.5 s\n",
      "Wall time: 2min 8s\n",
      "201006\n",
      "CPU times: user 9.48 s, sys: 1.59 s, total: 11.1 s\n",
      "Wall time: 2min 8s\n",
      "201007\n",
      "CPU times: user 9.43 s, sys: 1.54 s, total: 11 s\n",
      "Wall time: 2min 5s\n",
      "201008\n",
      "CPU times: user 9.52 s, sys: 1.55 s, total: 11.1 s\n",
      "Wall time: 2min 7s\n",
      "201106\n",
      "CPU times: user 9.31 s, sys: 1.65 s, total: 11 s\n",
      "Wall time: 2min 5s\n",
      "201107\n",
      "CPU times: user 9.83 s, sys: 1.58 s, total: 11.4 s\n",
      "Wall time: 2min 11s\n",
      "201108\n",
      "CPU times: user 9.57 s, sys: 1.5 s, total: 11.1 s\n",
      "Wall time: 2min 7s\n",
      "201206\n",
      "CPU times: user 9.88 s, sys: 1.22 s, total: 11.1 s\n",
      "Wall time: 2min 7s\n",
      "201207\n",
      "CPU times: user 10.2 s, sys: 946 ms, total: 11.1 s\n",
      "Wall time: 2min 8s\n",
      "201208\n",
      "CPU times: user 10.6 s, sys: 1.01 s, total: 11.6 s\n",
      "Wall time: 2min 14s\n",
      "201306\n",
      "CPU times: user 10.1 s, sys: 939 ms, total: 11 s\n",
      "Wall time: 2min 7s\n",
      "201307\n",
      "CPU times: user 10.4 s, sys: 951 ms, total: 11.3 s\n",
      "Wall time: 2min 10s\n",
      "201308\n",
      "CPU times: user 10.1 s, sys: 632 ms, total: 10.7 s\n",
      "Wall time: 2min 2s\n",
      "201406\n",
      "CPU times: user 11 s, sys: 816 ms, total: 11.8 s\n",
      "Wall time: 2min 10s\n",
      "201407\n",
      "CPU times: user 10.5 s, sys: 877 ms, total: 11.3 s\n",
      "Wall time: 2min 8s\n",
      "201408\n",
      "CPU times: user 9.98 s, sys: 1.25 s, total: 11.2 s\n",
      "Wall time: 2min 10s\n",
      "201506\n",
      "CPU times: user 9.59 s, sys: 1.45 s, total: 11 s\n",
      "Wall time: 2min 10s\n",
      "201507\n",
      "CPU times: user 9.4 s, sys: 1.4 s, total: 10.8 s\n",
      "Wall time: 2min 5s\n",
      "201508\n",
      "CPU times: user 9.56 s, sys: 1.69 s, total: 11.2 s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "years=range(2001,2016)\n",
    "for varcode in [\"128_132_v\"]:\n",
    "    for name in ['vietnam','myanmarwide','newbritainwide']:\n",
    "        print(varcode,name)\n",
    "        box=mountains[name][0]\n",
    "        months=months_perregion[name]\n",
    "        for y,m in itertools.product(years,months):\n",
    "            print(\"{}{:02}\".format(y,m))\n",
    "            ds = xr.open_mfdataset(ERA5D_PATH+\"e5.oper.an.pl/{}{:02}/e5.oper.an.pl.{}.*.nc\".format(y,m,varcode))\n",
    "            %time ds.sel(longitude=slice(box[0],box[1]),latitude=slice(box[3],box[2])).to_zarr(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.pl.{}.ll025sc.{}{:02}.{}.zarr\".format(varcode,y,m,name),mode=\"w\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createzarr_era5(name,varcode):\n",
    "    box=mountains[name][0]\n",
    "    years=range(2001,2016)\n",
    "    months=months_perregion[name]\n",
    "    for m in months:\n",
    "        var = xr.open_mfdataset([glob.glob(ERA5D_PATH+\"e5.oper.an.sfc/*/e5.oper.an.sfc.{}.*.{}{:02}0100_*.nc\".format(varcode,y,m))[0] for y in years])\n",
    "        var.sel(longitude=slice(box[0],box[1]),latitude=slice(box[3],box[2])).to_zarr(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.sfc.{}.ll025sc.{}-{}.{:02}.{}.zarr\".format(varcode,years[0],years[-1],m,name),mode=\"w\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createzarr_trmm(name):\n",
    "    box=mountains[name][0]\n",
    "    years=range(2001,2014)\n",
    "    months=months_perregion[name]\n",
    "    for m in months:\n",
    "        var = xr.open_mfdataset([glob.glob(CMIP6_FOLDER+\"obs4mip/NASA-GSFC/TRMM/observations/atmos/pr/3hr/NASA-GSFC/TRMM/*/*_{}{:02}*.nc\".format(y,m))[0] for y in years])\n",
    "        var = var.rename({'lat':'latitude','lon':'longitude'})\n",
    "        var = var.reindex(latitude=list(reversed(var.latitude)))\n",
    "        var.sel(longitude=slice(box[0],box[1]),latitude=slice(box[3],box[2])).to_zarr(\"/global/cscratch1/sd/qnicolas/regionsData/trmm.{}-{}.{:02}.{}.zarr\".format(years[0],years[-1],m,name),mode=\"w\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "def createzarr_gpm(name):\n",
    "    box=mountains[name][0]\n",
    "    years=range(2001,2016)\n",
    "    months=months_perregion[name]\n",
    "    for m in months:\n",
    "        var = xr.open_mfdataset([glob.glob(\"/global/cscratch1/sd/pnicknis/gpm/daily/3B-DAY.MS.MRG.3IMERG.{}{:02}*-S000000-E235959.V06.nc4\".format(y,m)) for y in years])\n",
    "        var = var.rename({'lat':'latitude','lon':'longitude'})\n",
    "        var = var.reindex(latitude=list(reversed(var.latitude)))\n",
    "        var['time'] = var.indexes['time'].to_datetimeindex()\n",
    "        var.sel(longitude=slice(box[0],box[1]),latitude=slice(box[3],box[2])).to_zarr(\"/global/cscratch1/sd/qnicolas/regionsData/gpm_imerg_v06.{}-{}.{:02}.{}.zarr\".format(years[0],years[-1],m,name),mode=\"w\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'julian', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'julian', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'julian', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'julian', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'julian', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/global/homes/q/qnicolas/.conda/envs/era5/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'julian', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 26s, sys: 2min 16s, total: 9min 42s\n",
      "Wall time: 15min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for name in ['myanmarwide','newbritainwide']:\n",
    "    createzarr_gpm(name)\n",
    "    createzarr_era5(name,\"228_246_100u\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time and space mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_daily(ds):\n",
    "    \"\"\"performs the same job as resample(time=\"1D\") but keeps missing days out\"\"\"\n",
    "    ds.coords['time'] = ds.time.dt.floor('1D')\n",
    "    return ds.groupby('time').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40secs\n",
    "%%time \n",
    "q_spatialmeans=[]\n",
    "for y,m in itertools.product(years,months):\n",
    "    qzarr = xr.open_zarr(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.pl.128_133_q.ll025sc.{}{:02}.ghats.zarr\".format(y,m)).Q\n",
    "    mask_ghats_era5= tilted_rect(qzarr,*precip_boxes[\"ghats\"],reverse=True)\n",
    "    q_spatialmeans.append(spatial_mean(resample_daily(qzarr),box=None,mask=mask_ghats_era5))\n",
    "\n",
    "temp=xr.concat(q_spatialmeans,dim='time')\n",
    "temp.to_netcdf(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.pl.128_133_q.ll025sc.1998-2013.JJA.ghats.upstreammean.nc\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.1 s, sys: 16.5 s, total: 1min 2s\n",
      "Wall time: 45.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "q_spatialmeans=[]\n",
    "for y,m in itertools.product(years,months):\n",
    "    qzarr = xr.open_zarr(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.pl.128_133_q.ll025sc.{}{:02}.ghats.zarr\".format(y,m)).Q\n",
    "    mask_ghats_era5_above= tilted_rect(qzarr,*precip_boxes[\"ghats\"])\n",
    "    q_spatialmeans.append(spatial_mean(resample_daily(qzarr),box=None,mask=mask_ghats_era5_above))\n",
    "\n",
    "temp=xr.concat(q_spatialmeans,dim='time')\n",
    "temp.to_netcdf(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.pl.128_133_q.ll025sc.1998-2013.JJA.ghats.mean.nc\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do June and July-august separately because they have a different number of days, so chunk size differ and saving to zarr would require rechunking\n",
    "def timespacemean_era5_JJA(name,varcode):\n",
    "    var_J =xr.open_zarr(\"/global/cscratch1/sd/qnicolas/temp/e5.oper.an.sfc.%s.ll025sc.1998-2013.J.%s.zarr\"%(varcode,name))\n",
    "    var_JA=xr.open_zarr(\"/global/cscratch1/sd/qnicolas/temp/e5.oper.an.sfc.%s.ll025sc.1998-2013.JA.%s.zarr\"%(varcode,name))\n",
    "    varname = list(var_J.data_vars)[0]\n",
    "    mask_ghats_era5= tilted_rect(var_J,*precip_boxes[name],reverse=True)\n",
    "    var_J_sm  = spatial_mean(resample_daily( var_J[varname]),box=None,mask=mask_ghats_era5)\n",
    "    var_JA_sm = spatial_mean(resample_daily(var_JA[varname]),box=None,mask=mask_ghats_era5)\n",
    "    xr.concat([var_J_sm,var_JA_sm],dim='time').sortby('time').to_netcdf(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.sfc.%s.ll025sc.1998-2013.JJA.%s.upstreammean.nc\"%(varcode,name))\n",
    "    \n",
    "def timespacemean_trmm_JJA(name):\n",
    "    var_J =xr.open_zarr(\"/global/cscratch1/sd/qnicolas/temp/trmm.1998-2013.J.%s.zarr\"%name)\n",
    "    var_JA=xr.open_zarr(\"/global/cscratch1/sd/qnicolas/temp/trmm.1998-2013.JA.%s.zarr\"%name)\n",
    "    mask_ghats_trmm= tilted_rect(var_J,*precip_boxes[name])\n",
    "    var_J_sm  = 86400*spatial_mean(resample_daily( var_J.pr),box=None,mask=mask_ghats_trmm)\n",
    "    var_JA_sm = 86400*spatial_mean(resample_daily(var_JA.pr),box=None,mask=mask_ghats_trmm)\n",
    "    xr.concat([var_J_sm,var_JA_sm],dim='time').sortby('time').to_netcdf(\"/global/cscratch1/sd/qnicolas/regionsData/trmm.1998-2013.JJA.%s.mean.nc\"%name)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in [\"ghats,\"\"myanmar\"    ,\"newbritain\"]:\n",
    "    timespacemean_era5_JJA(name,\"228_246_100u\")\n",
    "    timespacemean_era5_JJA(name,\"228_247_100v\")\n",
    "    timespacemean_trmm_JJA(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vietnam\n",
      "madagascar\n",
      "philippines\n",
      "sumatra\n",
      "malaysia\n",
      "CPU times: user 2min 13s, sys: 8.38 s, total: 2min 21s\n",
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "monthsinitials=['J','F','M','A','M','J','J','A','S','O','N','D']\n",
    "for name in [\"vietnam\",\"madagascar\",\"philippines\",\"sumatra\",\"malaysia\"]:\n",
    "    print(name)\n",
    "    months=months_perregion[name]\n",
    "    q_spatialmeans=[]\n",
    "    for y,m in itertools.product(years,months):\n",
    "        qzarr = xr.open_zarr(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.pl.128_133_q.ll025sc.{}{:02}.{}.zarr\".format(y,m,name)).Q\n",
    "        mask_era5= tilted_rect(qzarr,*precip_boxes[name],reverse=True)\n",
    "        q_spatialmeans.append(spatial_mean(resample_daily(qzarr),box=None,mask=mask_era5))\n",
    "    temp=xr.concat(q_spatialmeans,dim='time')\n",
    "    temp.to_netcdf(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.pl.128_133_q.ll025sc.1998-2013.%s.%s.upstreammean.nc\"%(''.join([monthsinitials[m-1] for m in months]),name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vietnam\n",
      "ghats\n",
      "madagascar\n",
      "myanmar\n",
      "newbritain\n",
      "philippines\n",
      "sumatra\n",
      "malaysia\n",
      "CPU times: user 3min 55s, sys: 13 s, total: 4min 8s\n",
      "Wall time: 5min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "monthsinitials=['J','F','M','A','M','J','J','A','S','O','N','D']\n",
    "for name in mountains:\n",
    "    print(name)\n",
    "    months=months_perregion[name]\n",
    "    t_spatialmeans=[]\n",
    "    for y,m in itertools.product(years,months):\n",
    "        tzarr = xr.open_zarr(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.pl.128_130_t.ll025sc.{}{:02}.{}.zarr\".format(y,m,name)).T\n",
    "        mask_era5= tilted_rect(tzarr,*precip_boxes[name],reverse=True)\n",
    "        t_spatialmeans.append(spatial_mean(resample_daily(tzarr),box=None,mask=mask_era5))\n",
    "    temp=xr.concat(t_spatialmeans,dim='time')\n",
    "    temp.to_netcdf(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.pl.128_130_t.ll025sc.1998-2013.%s.%s.upstreammean.nc\"%(''.join([monthsinitials[m-1] for m in months]),name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timespacemean_era5(name,varcode):\n",
    "    months=months_perregion[name]\n",
    "    var_months = [xr.open_zarr(\"/global/cscratch1/sd/qnicolas/temp/e5.oper.an.sfc.{}.ll025sc.1998-2013.{:02}.{}.zarr\".format(varcode,m,name)) for m in months]\n",
    "    varname = list(var_months[0].data_vars)[0]\n",
    "    mask_ghats_era5= tilted_rect(var_months[0],*precip_boxes[name],reverse=True)\n",
    "    var_months_sm  = [spatial_mean(resample_daily(var[varname]),box=None,mask=mask_ghats_era5) for var in var_months]\n",
    "    xr.concat(var_months_sm,dim='time').sortby('time').to_netcdf(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.sfc.%s.ll025sc.1998-2013.%s.%s.upstreammean.nc\"%(varcode,''.join([monthsinitials[m-1] for m in months]),name))\n",
    "    \n",
    "def timespacemean_trmm(name):\n",
    "    months=months_perregion[name]\n",
    "    var_months = [xr.open_zarr(\"/global/cscratch1/sd/qnicolas/temp/trmm.1998-2013.{:02}.{}.zarr\".format(m,name)) for m in months]\n",
    "    mask_ghats_trmm= tilted_rect(var_months[0],*precip_boxes[name])\n",
    "    var_months_sm  = [86400*spatial_mean(resample_daily( var.pr),box=None,mask=mask_ghats_trmm) for var in var_months]\n",
    "    xr.concat(var_months_sm,dim='time').sortby('time').to_netcdf(\"/global/cscratch1/sd/qnicolas/regionsData/trmm.1998-2013.%s.%s.mean.nc\"%(''.join([monthsinitials[m-1] for m in months]),name))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 s, sys: 914 ms, total: 20.7 s\n",
      "Wall time: 22.9 s\n",
      "CPU times: user 19.5 s, sys: 805 ms, total: 20.3 s\n",
      "Wall time: 22.8 s\n",
      "CPU times: user 21.8 s, sys: 967 ms, total: 22.7 s\n",
      "Wall time: 24.9 s\n",
      "CPU times: user 19.9 s, sys: 774 ms, total: 20.7 s\n",
      "Wall time: 22.7 s\n",
      "CPU times: user 19.3 s, sys: 703 ms, total: 20 s\n",
      "Wall time: 22.2 s\n",
      "CPU times: user 18.7 s, sys: 636 ms, total: 19.3 s\n",
      "Wall time: 21.6 s\n",
      "CPU times: user 18.4 s, sys: 802 ms, total: 19.2 s\n",
      "Wall time: 22 s\n",
      "CPU times: user 18.5 s, sys: 861 ms, total: 19.4 s\n",
      "Wall time: 21.5 s\n",
      "CPU times: user 21.1 s, sys: 1.05 s, total: 22.2 s\n",
      "Wall time: 24.4 s\n",
      "CPU times: user 29.2 s, sys: 893 ms, total: 30.1 s\n",
      "Wall time: 32.9 s\n",
      "CPU times: user 28.9 s, sys: 1.16 s, total: 30.1 s\n",
      "Wall time: 33 s\n",
      "CPU times: user 30.4 s, sys: 962 ms, total: 31.4 s\n",
      "Wall time: 34.8 s\n",
      "CPU times: user 19 s, sys: 589 ms, total: 19.6 s\n",
      "Wall time: 22.1 s\n",
      "CPU times: user 20.1 s, sys: 922 ms, total: 21 s\n",
      "Wall time: 23.4 s\n",
      "CPU times: user 19.2 s, sys: 591 ms, total: 19.8 s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "for name in [\"vietnam\",\"madagascar\",\"philippines\",\"sumatra\",\"malaysia\"]:\n",
    "    %time timespacemean_era5(name,\"228_246_100u\")\n",
    "    %time timespacemean_era5(name,\"228_247_100v\")\n",
    "    %time timespacemean_trmm(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12-hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.9 s, sys: 14.1 s, total: 54 s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "q_spatialmeans=[]\n",
    "for y,m in itertools.product(years,months):\n",
    "    qzarr = xr.open_zarr(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.pl.128_133_q.ll025sc.{}{:02}.ghats.zarr\".format(y,m)).Q\n",
    "    mask_ghats_era5_above= tilted_rect(qzarr,*precip_boxes[\"ghats\"])\n",
    "    q_spatialmeans.append(spatial_mean(qzarr.coarsen(time=12).mean(),box=None,mask=mask_ghats_era5_above))\n",
    "\n",
    "temp=xr.concat(q_spatialmeans,dim='time')\n",
    "temp['time']=temp['time']+pd.Timedelta(\"30m\")\n",
    "temp.to_netcdf(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.pl.128_133_q.ll025sc.1998-2013.JJA.12h.ghats.mean.nc\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do June and July-august separately because they have a different number of days, so chunk size differ and saving to zarr would require rechunking\n",
    "def halfdayspacemean_era5(varcode):\n",
    "    var_J =xr.open_zarr(\"/global/cscratch1/sd/qnicolas/temp/e5.oper.an.sfc.%s.ll025sc.1998-2013.J.ghats.zarr\"%varcode)\n",
    "    var_JA=xr.open_zarr(\"/global/cscratch1/sd/qnicolas/temp/e5.oper.an.sfc.%s.ll025sc.1998-2013.JA.ghats.zarr\"%varcode)\n",
    "    varname = list(var_J.data_vars)[0]\n",
    "    mask_ghats_era5= tilted_rect(var_J,*precip_boxes[\"ghats\"],reverse=True)\n",
    "    var_J_sm  = spatial_mean( var_J[varname].coarsen(time=12).mean(),box=None,mask=mask_ghats_era5)\n",
    "    var_JA_sm = spatial_mean(var_JA[varname].coarsen(time=12).mean(),box=None,mask=mask_ghats_era5)\n",
    "    temp = xr.concat([var_J_sm,var_JA_sm],dim='time').sortby('time')\n",
    "    temp['time']=temp['time']+pd.Timedelta(\"30m\")\n",
    "    temp.to_netcdf(\"/global/cscratch1/sd/qnicolas/regionsData/e5.oper.an.sfc.%s.ll025sc.1998-2013.JJA.12h.ghats.upstreammean.nc\"%varcode)\n",
    "    \n",
    "def halfdayspacemean_trmm():\n",
    "    var_J =xr.open_zarr(\"/global/cscratch1/sd/qnicolas/temp/trmm.1998-2013.J.ghats.zarr\")\n",
    "    var_JA=xr.open_zarr(\"/global/cscratch1/sd/qnicolas/temp/trmm.1998-2013.JA.ghats.zarr\")\n",
    "    mask_ghats_trmm= tilted_rect(var_J,*precip_boxes[\"ghats\"])\n",
    "    var_J_sm  = 86400*spatial_mean( var_J.pr.coarsen(time=4).mean(),box=None,mask=mask_ghats_trmm)\n",
    "    var_JA_sm = 86400*spatial_mean(var_JA.pr.coarsen(time=4).mean(),box=None,mask=mask_ghats_trmm)\n",
    "    xr.concat([var_J_sm,var_JA_sm],dim='time').sortby('time').to_netcdf(\"/global/cscratch1/sd/qnicolas/regionsData/trmm.1998-2013.JJA.12h.ghats.mean.nc\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.42 s, sys: 955 ms, total: 4.38 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "halfdayspacemean_era5(\"228_246_100u\")\n",
    "halfdayspacemean_era5(\"228_247_100v\")\n",
    "halfdayspacemean_trmm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ERA5",
   "language": "python",
   "name": "era5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
